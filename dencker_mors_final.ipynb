{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":102516,"databundleVersionId":12359416,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Youtube Sentiment Analysis\nMORS 2025 Competition\n\nCPT Jonathan Dencker\n\nCPT John McCormick","metadata":{}},{"cell_type":"code","source":"import os, sys, json, uuid, hashlib, time, platform, subprocess, random\nfrom datetime import datetime\nfrom pathlib import Path\nimport pandas as pd\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig, LogitsProcessor\nfrom tqdm.notebook import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ntqdm.pandas()\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"   # silence TF/XLA info/warnings\nos.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"    # keep JAX off the GPU, if present\nos.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n\ndef set_seed(seed: int = 42):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\nRUN_ID = uuid.uuid4().hex[:8]\nOUT_DIR = Path(f\"/kaggle/working/run_{RUN_ID}\")\nOUT_DIR.mkdir(parents=True, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:42:01.050599Z","iopub.execute_input":"2025-10-15T14:42:01.051850Z","iopub.status.idle":"2025-10-15T14:42:01.061974Z","shell.execute_reply.started":"2025-10-15T14:42:01.051815Z","shell.execute_reply":"2025-10-15T14:42:01.061231Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# from huggingface_hub import snapshot_download\n\n# snapshot_download(\n#     repo_id=\"Qwen/Qwen2.5-7B-Instruct\",\n#     local_dir=\"/kaggle/working/models/Qwen2.5-7B-Instruct\"\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T12:31:30.303567Z","iopub.execute_input":"2025-10-15T12:31:30.304097Z","iopub.status.idle":"2025-10-15T12:33:19.479948Z","shell.execute_reply.started":"2025-10-15T12:31:30.304062Z","shell.execute_reply":"2025-10-15T12:33:19.479023Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py:202: UserWarning: The `local_dir_use_symlinks` argument is deprecated and ignored in `snapshot_download`. Downloading to a local directory does not use symlinks anymore.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 14 files:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4672cb753bff42a2a4aa6e3c05fbd643"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53f57940bc21457ea27443f6de1e6766"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40465866e7ef4bf4b660638f60aa955d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edda670bacd249728b08727ec2ee9d28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6e444fe5dfb4094a5994a71b49d8fdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"LICENSE: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dca00da286e94403885cbb29fd927b71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c12932b955bf48af859d9803429d3f2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b35355b215a457fa6bbe9a90434a0e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5959dc451ef435b95711abda848cc7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1b8a8563e30462a9bb6e08838c5ba1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"989f8442a3144e0689774dc6fb9848b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c68f15e7930248c1b858c93298e06c78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"868ea91427ea454983bd82102452cae1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd7894644878494281c3e51e8471cb20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a891835e23af4fbca1c144204ee314c7"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/models/Qwen2.5-7B-Instruct'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Load Model\nMODEL_PATH=\"/kaggle/working/models/Qwen2.5-7B-Instruct\"\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch_dtype = torch.bfloat16 if device == \"cuda\" and torch.cuda.is_bf16_supported() else torch.float16\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, use_fast=True, padding_side=\"left\")\n\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token \n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_PATH,\n    torch_dtype=torch_dtype,\n    device_map=\"auto\" if device == \"cuda\" else None\n)\n\nmodel.config.pad_token_id = tokenizer.pad_token_id\n\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:42:05.655398Z","iopub.execute_input":"2025-10-15T14:42:05.656289Z","iopub.status.idle":"2025-10-15T14:42:43.418302Z","shell.execute_reply.started":"2025-10-15T14:42:05.656252Z","shell.execute_reply":"2025-10-15T14:42:43.417559Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d3dfbc66e384c968b63324d6f8c31c3"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(152064, 3584)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen2DecoderLayer(\n        (self_attn): Qwen2Attention(\n          (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n          (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n          (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n          (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Prompt Template\nLABELS = [\"for\", \"against\", \"neutral\"]\nLABEL_SET = set(LABELS)\n\nSYSTEM_MSG = \"You are a precise classifier. Only output valid JSON with two keys and no extra text.\"\nUSER_TMPL = \"\"\"Classify the following YouTube comment for two stances.\nReturn ONLY JSON: {{\"stance_toward_army\": \"...\", \"stance_toward_video\": \"...\"}}.\nAllowed values: \"for\", \"against\", \"neutral\".\n\nComment:\n<<<{text}>>>\n\"\"\"\n\ndef build_prompt(comment: str) -> str:\n    # Llama/Qwen/Mistral instruction-style prompt\n    return (\n        f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \\\n            \\n{SYSTEM_MSG} \\\n            \\n<|eot_id|><|start_header_id|>user<|end_header_id|> \\\n            \\n{USER_TMPL.format(text=comment)} \\\n            \\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\"\n    )\n\ngen_cfg = GenerationConfig(\n    max_new_tokens=64,     # small: JSON with two words\n    top_p=1.0,\n    do_sample=False,\n    pad_token_id=tokenizer.pad_token_id,\n    eos_token_id=tokenizer.eos_token_id\n)\n\n\ndef classify_batch(comments):\n    prompts = [build_prompt(c) for c in comments]\n    encoding = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True)\n    # unpacks tokenizer encoding.keys() -> dict_keys(['input_ids', 'attention_mask'])\n    enc = {k: v.to(model.device) for k, v in encoding.items()}\n\n    with torch.no_grad():\n        outputs = model.generate(\n            **enc,\n            generation_config=gen_cfg\n        )\n        \n    # left padding -> slice using actual (non-padded) lengths\n    input_lengths = enc[\"attention_mask\"].sum(dim=1)\n\n    decoded = [\n        tokenizer.decode(\n            outputs[i, int(input_lengths[i].item()):],\n            skip_special_tokens=True\n        )\n        for i in range(outputs.size(0))\n    ]\n    return decoded\n\n\ndef parse_json_safe(s: str):\n    # Extract first JSON block\n    start = s.find(\"{\")\n    end = s.rfind(\"}\")\n    if start != -1 and end != -1 and end > start:\n        frag = s[start:end+1]\n        try:\n            obj = json.loads(frag)\n            ms = str(obj.get(\"stance_toward_army\",\"\")).strip().lower()\n            vs = str(obj.get(\"stance_toward_video\",\"\")).strip().lower()\n            # fallback mapping in case model outputs synonyms\n            syn = {\"pro\":\"for\",\"support\":\"for\",\"anti\":\"against\",\"oppose\":\"against\",\"opposed\":\"against\",\"neutrality\":\"neutral\"}\n            ms = syn.get(ms, ms)\n            vs = syn.get(vs, vs)\n            if ms not in LABEL_SET: ms = \"neutral\"\n            if vs not in LABEL_SET: vs = \"neutral\"\n            return {\"stance_toward_army\": ms, \"stance_toward_video\": vs, \"raw\": frag}\n        except Exception:\n            pass\n    return {\"stance_toward_army\":\"neutral\",\"stance_toward_video\":\"neutral\",\"raw\": s[:2000]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:42:49.049324Z","iopub.execute_input":"2025-10-15T14:42:49.049904Z","iopub.status.idle":"2025-10-15T14:42:49.060762Z","shell.execute_reply.started":"2025-10-15T14:42:49.049878Z","shell.execute_reply":"2025-10-15T14:42:49.059977Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"BATCH = 16\nresults = []\n\ndf = pd.read_csv(\"/kaggle/input/2025-mors-data-challenge/train.csv\")\ndf = df.head(32)\n\nfor i in tqdm(range(0, len(df), BATCH), desc=\"Batches Processed:\", position=0):\n    chunk = df.iloc[i:i+BATCH]\n    outs = []\n    for comment in tqdm(chunk[\"comment\"].tolist(), desc=f\"Batch {i/BATCH+1}\", leave=False, position=1):\n        outs.extend(classify_batch([comment]))\n        \n    parsed = list(map(parse_json_safe, outs))\n    \n    for uid, p in zip(chunk[\"id\"], parsed):\n        results.append({\n            \"id\": uid,\n            \"stance_toward_army\": p[\"stance_toward_army\"],\n            \"stance_toward_video\": p[\"stance_toward_video\"],\n            \"raw_model_out\": p[\"raw\"]\n        })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:42:54.664447Z","iopub.execute_input":"2025-10-15T14:42:54.664728Z","iopub.status.idle":"2025-10-15T14:58:29.771199Z","shell.execute_reply.started":"2025-10-15T14:42:54.664708Z","shell.execute_reply":"2025-10-15T14:58:29.770234Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches Processed::   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9ab45f724414477b6c4adc266851f53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batch 1.0:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batch 2.0:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"preds_with_raw_output = pd.DataFrame(results)\npreds_for_submission = preds_with_raw_output[[\"id\", \"stance_toward_army\", \"stance_toward_video\"]]\npreds_with_raw_output.to_parquet(OUT_DIR / \"predictions.parquet\", index=False)\npreds_for_submission.to_csv(OUT_DIR / \"submission.csv\", index=False)\n\nprint(\"Saved:\")\nprint(\" - Full predictions with raw model output: \", OUT_DIR / \"predictions.parquet\")\nprint(\" - Clean submission file: \", OUT_DIR / \"submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:58:29.772514Z","iopub.execute_input":"2025-10-15T14:58:29.772851Z","iopub.status.idle":"2025-10-15T14:58:30.240632Z","shell.execute_reply.started":"2025-10-15T14:58:29.772832Z","shell.execute_reply":"2025-10-15T14:58:30.239755Z"}},"outputs":[{"name":"stdout","text":"Saved:\n - Full predictions with raw model output:  /kaggle/working/run_7aa009b2/predictions.parquet\n - Clean submission file:  /kaggle/working/run_7aa009b2/submission.csv\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(preds_for_submission)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:58:30.241539Z","iopub.execute_input":"2025-10-15T14:58:30.241928Z","iopub.status.idle":"2025-10-15T14:58:30.258592Z","shell.execute_reply.started":"2025-10-15T14:58:30.241898Z","shell.execute_reply":"2025-10-15T14:58:30.257756Z"}},"outputs":[{"name":"stdout","text":"                                                   id stance_toward_army  \\\n0                          UgzgltD6aB_xznJOGPp4AaABAg            neutral   \n1                          Ugzoj2u6j6yRXAH9-PV4AaABAg            neutral   \n2                          UgycFd1HUYGSHfIhzDB4AaABAg            against   \n3                          Ugzi6_ly_QKkYwBMjc54AaABAg                for   \n4                          UgwHIvTiNh5KqIUJHwt4AaABAg                for   \n5                          UgwM8uKpA9cgNrAlebF4AaABAg            against   \n6                          UgzmahQHNmkXZsL7_-h4AaABAg            neutral   \n7                          Ugyrsd7JXLL53mfGyKB4AaABAg            neutral   \n8                          UgySHsZ9Y4UMoXPbgqB4AaABAg            neutral   \n9                          UgwawVkimE9UITpWtDd4AaABAg                for   \n10                         Ugyk4AqmVuNhEGOmAmV4AaABAg                for   \n11                         UgwItktcdZrNX_1EFJ14AaABAg                for   \n12                         UgxUDC6J4sHGAkiiQq54AaABAg            against   \n13                         UgzL1TNdMU91rCrsL5l4AaABAg            neutral   \n14  UgzL1TNdMU91rCrsL5l4AaABAg.AHLp_O7sFU_AHMLVndXbs_            neutral   \n15  UgzL1TNdMU91rCrsL5l4AaABAg.AHLp_O7sFU_AHNZxmK0IV_            against   \n16                         UgzUMDz5fjpwSNLYqDl4AaABAg            neutral   \n17                         UgzG5P6HRNkKUQXIH9J4AaABAg            against   \n18  UgzG5P6HRNkKUQXIH9J4AaABAg.AHLRHb4otd-AHLWKwxc6s0            neutral   \n19  UgzG5P6HRNkKUQXIH9J4AaABAg.AHLRHb4otd-AHMLYwusEU7            neutral   \n20                         UgxW1BTZmUJBcIvVMPJ4AaABAg            neutral   \n21                         UgwxLVxnH8p3DIuA7S94AaABAg                for   \n22                         Ugz6zHDLTkmCYITyLY14AaABAg            neutral   \n23                         UgxKGeLskfgBjYZdJ4p4AaABAg                for   \n24                         UgxOLANtR7lBws-nTDx4AaABAg            neutral   \n25                         UgyA6Um-5fTQe3RCSLN4AaABAg                for   \n26                         UgyDbo5lwOktGxLIeXV4AaABAg                for   \n27                         UgyFSzUKPFFESeoqugt4AaABAg                for   \n28                         Ugw9M-6I1BA58FXEbo54AaABAg            neutral   \n29                         UgzdhDo6XMGtJfaLd_x4AaABAg            neutral   \n30                         UgzxQGvKKT3-l_bcEkN4AaABAg                for   \n31                         Ugy9B6_5AZtF3iuXNIR4AaABAg                for   \n\n   stance_toward_video  \n0                  for  \n1              neutral  \n2              neutral  \n3                  for  \n4                  for  \n5              neutral  \n6              neutral  \n7              neutral  \n8              neutral  \n9              neutral  \n10                 for  \n11             neutral  \n12             against  \n13             against  \n14             neutral  \n15             against  \n16             neutral  \n17             neutral  \n18             against  \n19             against  \n20                 for  \n21             neutral  \n22             neutral  \n23             neutral  \n24             against  \n25             neutral  \n26             neutral  \n27             neutral  \n28             neutral  \n29             against  \n30             neutral  \n31             neutral  \n","output_type":"stream"}],"execution_count":9}]}